{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()\n",
        "# get a handle to the workspace\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: quick-starts-ws-259362\nAzure region: eastus2\nSubscription id: 9b72f9e6-56c5-4c16-991b-19c652994860\nResource group: aml-quickstarts-259362\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1716095090941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "\n",
        "\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "cpu_cluster_name = \"aml-first-compute\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # To use a different region for the compute, add a location='<region>' parameter\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n\nRunning\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1716093234135
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "import os\n",
        "\n",
        "# Specify parameter sampler\n",
        "ps = RandomParameterSampling({'--C':uniform(0.1,1),'--max_iter':choice(50,100,200)})\n",
        "\n",
        "# Specify a Policy\n",
        "policy = BanditPolicy(evaluation_interval=2,slack_factor=1)\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "# Setup environment for your training run\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')\n",
        "\n",
        "# Create a ScriptRunConfig Object to specify the configuration details of your training job\n",
        "src = ScriptRunConfig(source_directory='.',\n",
        "                            script='train.py',\n",
        "                            #arguments=['--C', arg1_val, '--arg2', arg2_val],\n",
        "                            compute_target=cpu_cluster,\n",
        "                            environment=sklearn_env)\n",
        "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,hyperparameter_sampling=ps,\n",
        "primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,primary_metric_name='Accuracy',max_concurrent_runs=4,max_total_runs=30,policy=policy)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1716093681085
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "experiment = Experiment(workspace=ws, name='hyperdrive_example')\n",
        "hyperdrive_run = experiment.submit(hyperdrive_config)\n",
        "hyperdrive_run.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d\nWeb View: https://ml.azure.com/runs/HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-259362/workspaces/quick-starts-ws-259362&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2024-05-19T04:41:28.803985][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n[2024-05-19T04:41:29.3745189Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_1' \n[2024-05-19T04:41:29.3009719Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_0' \n[2024-05-19T04:41:29.536774][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n[2024-05-19T04:41:29.5920209Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_2' \n[2024-05-19T04:41:29.7090890Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_3' \n[2024-05-19T04:41:30.1844153Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_1' \n[2024-05-19T04:41:30.2395147Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_3' \n[2024-05-19T04:41:30.2426235Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_2' \n[2024-05-19T04:41:30.4146832Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_0' \n[2024-05-19T04:52:59.154809][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n[2024-05-19T04:52:59.339100][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n[2024-05-19T04:52:59.4446130Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_4' \n[2024-05-19T04:53:00.0555080Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_4' \n[2024-05-19T04:53:29.160467][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\n[2024-05-19T04:53:29.5717940Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_5' \n[2024-05-19T04:53:29.6848472Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_6' \n[2024-05-19T04:53:29.7968933Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_7' \n[2024-05-19T04:53:29.8346702Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_5' \n[2024-05-19T04:53:29.761611][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\n[2024-05-19T04:53:30.0416622Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_7' \n[2024-05-19T04:53:30.1920539Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_6' \n[2024-05-19T04:53:59.714156][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n[2024-05-19T04:53:59.999871][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n[2024-05-19T04:54:00.1268011Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_8' \n[2024-05-19T04:54:00.4151900Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_8' \n[2024-05-19T04:54:29.483684][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\n[2024-05-19T04:54:29.8391406Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_9' \n[2024-05-19T04:54:29.9437174Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_10' \n[2024-05-19T04:54:30.1017971Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_9' \n[2024-05-19T04:54:29.993233][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\n[2024-05-19T04:54:30.1805431Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_11' \n[2024-05-19T04:54:30.1686943Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_10' \n[2024-05-19T04:54:30.4388798Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_11' \n[2024-05-19T04:54:59.568314][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n[2024-05-19T04:54:59.9205584Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_12' \n[2024-05-19T04:54:59.878721][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n[2024-05-19T04:55:00.1695410Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_12' \n[2024-05-19T04:55:29.633364][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\n[2024-05-19T04:55:30.1399114Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_13' \n[2024-05-19T04:55:30.2543713Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_14' \n[2024-05-19T04:55:30.3531156Z][SCHEDULER][INFO]Scheduling job, id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_15' \n[2024-05-19T04:55:30.296354][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\n[2024-05-19T04:55:30.5114172Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_13' \n[2024-05-19T04:55:30.5881414Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_15' \n[2024-05-19T04:55:30.6875248Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_eae21f0a-8674-4c06-b2d0-49d96a2cc59d_14' \n"
        },
        {
          "output_type": "error",
          "ename": "ExperimentExecutionException",
          "evalue": "ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py:849\u001b[0m, in \u001b[0;36mRun.wait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_post_processing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_post_processing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_details()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py:1048\u001b[0m, in \u001b[0;36mRun._stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m   1047\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m-> 1048\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_before_polling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpoll_start_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_details()  \u001b[38;5;66;03m# TODO use FileWatcher\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m experiment \u001b[38;5;241m=\u001b[39m Experiment(workspace\u001b[38;5;241m=\u001b[39mws, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperdrive_example\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m hyperdrive_run \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39msubmit(hyperdrive_config)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mhyperdrive_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py:860\u001b[0m, in \u001b[0;36mRun.wait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    856\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    857\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    858\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 860\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExperimentExecutionException(error_message)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m     running_states \u001b[38;5;241m=\u001b[39m RUNNING_STATES\n",
            "\u001b[0;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1716094566973
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "print(f\"Best run arguments: {best_run.get_details()['runDefinition']['arguments']}\")\n",
        "print(f\"Best run metrics: {best_run.get_metrics()}\")\n",
        "print(f\"Best run file names: {best_run.get_file_names()}\")\n",
        "joblib.dump(value=best_run.id, filename=\"./outputs/hyperdrive_model.joblib\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best run arguments: ['--C', '0.7209608007003498', '--max_iter', '200']\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m best_run \u001b[38;5;241m=\u001b[39m hyperdrive_run\u001b[38;5;241m.\u001b[39mget_best_run_by_primary_metric()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest run arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run\u001b[38;5;241m.\u001b[39mget_details()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunDefinition\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest run metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run\u001b[38;5;241m.\u001b[39mget_metrics()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest run file names: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_run\u001b[38;5;241m.\u001b[39mget_file_names()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(value\u001b[38;5;241m=\u001b[39mbest_run\u001b[38;5;241m.\u001b[39mid, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./outputs/hyperdrive_model.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py:1348\u001b[0m, in \u001b[0;36mRun.get_metrics\u001b[0;34m(self, name, recursive, run_type, populate)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, populate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve the metrics logged to the run.\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m \n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03m    If ``recursive`` is True (False by default), then fetch metrics for runs in the given run's subtree.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;124;03m    :rtype: dict\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpopulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopulate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_run_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root_run_id\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_run_impl/run_history_facade.py:390\u001b[0m, in \u001b[0;36mRunHistoryFacade.get_metrics\u001b[0;34m(self, name, recursive, run_type, populate, root_run_id, run_ids, use_batch)\u001b[0m\n\u001b[1;32m    387\u001b[0m     run_ids \u001b[38;5;241m=\u001b[39m descendant_ids \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_id]\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_v2_metrics:\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_metrics_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopulate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43martifact_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mdata_container\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_container_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mget_all_metrics(run_ids\u001b[38;5;241m=\u001b[39mrun_ids, populate\u001b[38;5;241m=\u001b[39mpopulate, artifact_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifacts,\n\u001b[1;32m    395\u001b[0m                                     data_container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_container_id, name\u001b[38;5;241m=\u001b[39mname)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/metrics_client.py:314\u001b[0m, in \u001b[0;36mMetricsClient.get_all_metrics_v2\u001b[0;34m(self, name, run_ids, populate, artifact_client, data_container, after_timestamp, custom_headers)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_metrics_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, run_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, populate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, artifact_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    311\u001b[0m                        data_container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, after_timestamp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, custom_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# Compared to v1, the following are ignored; convert_to_object (default False), use_batch(default True),\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# metric_types and merge_strategy_type, all are not exposed to the SDK users.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics_for_run_ids_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mafter_timestamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mpopulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopulate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mdata_container\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_container\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/metrics_client.py:300\u001b[0m, in \u001b[0;36mMetricsClient.get_metrics_for_run_ids_v2\u001b[0;34m(self, name, run_ids, start_time, end_time, populate, artifact_client, data_container, custom_headers)\u001b[0m\n\u001b[1;32m    298\u001b[0m all_run_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_id] \u001b[38;5;28;01mif\u001b[39;00m run_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m run_ids\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run_id \u001b[38;5;129;01min\u001b[39;00m all_run_ids:\n\u001b[0;32m--> 300\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics_for_run_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopulate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43martifact_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_container\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_container\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metrics) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    305\u001b[0m         returned_metrics_for_runs[run_id] \u001b[38;5;241m=\u001b[39m metrics\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/metrics_client.py:282\u001b[0m, in \u001b[0;36mMetricsClient.get_metrics_for_run_v2\u001b[0;34m(self, run_id, name, start_time, end_time, populate, artifact_client, data_container, custom_headers)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m         metric_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_metric_names_for_run_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError getting metrics for run id \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(run_id))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/metrics_client.py:377\u001b[0m, in \u001b[0;36mMetricsClient.list_metric_names_for_run_id\u001b[0;34m(self, run_id, custom_headers)\u001b[0m\n\u001b[1;32m    372\u001b[0m metric_def_dtos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_with_workspace_run_arguments(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mlist_metrics,\n\u001b[1;32m    373\u001b[0m                                                              request_dto,\n\u001b[1;32m    374\u001b[0m                                                              is_paginated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    375\u001b[0m                                                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_def_dto \u001b[38;5;129;01min\u001b[39;00m metric_def_dtos:\n\u001b[1;32m    378\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(metric_def_dto\u001b[38;5;241m.\u001b[39mmetric_key\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_restclient/clientbase.py:264\u001b[0m, in \u001b[0;36mClientBase._call_paginated_api\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m next_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_api(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 264\u001b[0m     paginated_dto \u001b[38;5;241m=\u001b[39m \u001b[43mnext_page\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mawaiter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mApiPagination\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paginated_dto:\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_common/async_utils/async_task.py:58\u001b[0m, in \u001b[0;36mAsyncTask.wait\u001b[0;34m(self, awaiter_name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaitingTask\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m     57\u001b[0m     context\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAwaiter is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(awaiter_name))\n\u001b[0;32m---> 58\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_common/async_utils/async_task.py:16\u001b[0m, in \u001b[0;36mbasic_handler\u001b[0;34m(future, _)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbasic_handler\u001b[39m(future, _):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns future's result directly with no error handling\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/concurrent/futures/_base.py:434\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1716094576614
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "paths=\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "ds=TabularDatasetFactory.from_delimited_files(paths)\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1716094582796
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "import pandas as pd\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(ds)\n",
        "\n",
        "train_df = pd.concat([x, y], axis=1)\n",
        "train_df_path = os.path.join(\".\", 'train.csv')\n",
        "train_df.to_csv(train_df_path)\n",
        "data_store = ws.get_default_datastore()\n",
        "data_store.upload(src_dir=\".\", target_path=\".\")\n",
        "train_ds = TabularDatasetFactory.from_delimited_files(data_store.path(\"azureml://subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-259362/workspaces/quick-starts-ws-259362/datastores/workspaceblobstore/paths/UI/2024-05-19_050201_UTC/bankmarketing_train.csv\"))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 18 files\n"
        },
        {
          "output_type": "error",
          "ename": "ClientAuthenticationError",
          "evalue": "Operation returned an invalid status 'Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.'\nErrorCode:AuthenticationFailed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientAuthenticationError\u001b[0m                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m train_df\u001b[38;5;241m.\u001b[39mto_csv(train_df_path)\n\u001b[1;32m      9\u001b[0m data_store \u001b[38;5;241m=\u001b[39m ws\u001b[38;5;241m.\u001b[39mget_default_datastore()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mdata_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m TabularDatasetFactory\u001b[38;5;241m.\u001b[39mfrom_delimited_files(data_store\u001b[38;5;241m.\u001b[39mpath(train_df_path))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_deprecation.py:26\u001b[0m, in \u001b[0;36mdeprecated.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     _warn_deprecation(target, replacement)  \u001b[38;5;66;03m# only raise warning for top-level invocation\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     _warning_silenced_for \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m---> 26\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _warning_silenced_for \u001b[38;5;241m==\u001b[39m target:\n\u001b[1;32m     28\u001b[0m     _warning_silenced_for \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/azure_storage_datastore.py:926\u001b[0m, in \u001b[0;36mAzureBlobDatastore.upload\u001b[0;34m(self, src_dir, target_path, overwrite, show_progress)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_credential(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    925\u001b[0m target_path \u001b[38;5;241m=\u001b[39m target_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 926\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_upload_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_upload_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_file_path\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblob_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_blob_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_file_path\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblob_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_blob_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_blob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBlockBlob\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m module_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished AzureBlobDatastore.upload with count=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(count))\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataReference(datastore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, path_on_datastore\u001b[38;5;241m=\u001b[39mtarget_path)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/azure_storage_datastore.py:330\u001b[0m, in \u001b[0;36mAbstractAzureStorageDatastore._start_upload_task\u001b[0;34m(self, paths_to_upload, overwrite, exists, show_progress, task_generator)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (src_file_path, target_file_path) \u001b[38;5;129;01min\u001b[39;00m paths_to_upload:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_file_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    331\u001b[0m             estimated_total \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    332\u001b[0m             console(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget already exists. Skipping upload for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target_file_path))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/azure_storage_datastore.py:929\u001b[0m, in \u001b[0;36mAzureBlobDatastore.upload.<locals>.<lambda>\u001b[0;34m(target_file_path)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_credential(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    925\u001b[0m target_path \u001b[38;5;241m=\u001b[39m target_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    926\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_upload_task(\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_upload_from_dir(src_dir, target_path),\n\u001b[1;32m    928\u001b[0m     overwrite,\n\u001b[0;32m--> 929\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m target_file_path: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblob_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_blob_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_file_path\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    933\u001b[0m     show_progress,\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m target, source: \u001b[38;5;28;01mlambda\u001b[39;00m: [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_service\u001b[38;5;241m.\u001b[39mget_blob_client(\n\u001b[1;32m    935\u001b[0m         container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_name,\n\u001b[1;32m    936\u001b[0m         blob\u001b[38;5;241m=\u001b[39mtarget\n\u001b[1;32m    937\u001b[0m     )\u001b[38;5;241m.\u001b[39mupload_blob(\n\u001b[1;32m    938\u001b[0m         f, blob_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlockBlob\u001b[39m\u001b[38;5;124m\"\u001b[39m, overwrite\u001b[38;5;241m=\u001b[39moverwrite\n\u001b[1;32m    939\u001b[0m     ), f\u001b[38;5;241m.\u001b[39mclose()) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mopen\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)]][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    940\u001b[0m )\n\u001b[1;32m    941\u001b[0m module_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished AzureBlobDatastore.upload with count=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(count))\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataReference(datastore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, path_on_datastore\u001b[38;5;241m=\u001b[39mtarget_path)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_vendor/azure_storage/blob/_blob_client.py:1178\u001b[0m, in \u001b[0;36mBlobClient.exists\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m         \u001b[43mprocess_storage_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ResourceNotFoundError:\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_vendor/azure_storage/blob/_shared/response_handlers.py:181\u001b[0m, in \u001b[0;36mprocess_storage_error\u001b[0;34m(storage_error)\u001b[0m\n\u001b[1;32m    178\u001b[0m error\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (error\u001b[38;5;241m.\u001b[39mmessage,)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise error from None\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
            "File \u001b[0;32m<string>:1\u001b[0m\n",
            "\u001b[0;31mClientAuthenticationError\u001b[0m: Operation returned an invalid status 'Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.'\nErrorCode:AuthenticationFailed"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1716094834368
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = Dataset.get_all(ws)\n",
        "for name, dataset in datasets.items():\n",
        "    print(f\"Name: {name}, Dataset: {dataset}\")\n"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716095099042
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset, Experiment\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, name=\"train_df\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "UserErrorException",
          "evalue": "UserErrorException:\n\tMessage: Cannot find dataset registered with name \"train_df\" (version: None) in the workspace.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Cannot find dataset registered with name \\\"train_df\\\" (version: None) in the workspace.\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workspace, Dataset, Experiment\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoMLConfig\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_df\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m al:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(al, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_info\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/abstract_dataset.py:94\u001b[0m, in \u001b[0;36mAbstractDataset.get_by_name\u001b[0;34m(workspace, name, version)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@track\u001b[39m(_get_logger, activity_type\u001b[38;5;241m=\u001b[39m_PUBLIC_API)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_by_name\u001b[39m(workspace, name, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a registered Dataset from workspace by its registration name.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    :param workspace: The existing AzureML workspace in which the Dataset was registered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    :rtype: typing.Union[azureml.data.TabularDataset, azureml.data.FileDataset]\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mAbstractDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     AbstractDataset\u001b[38;5;241m.\u001b[39m_track_lineage([dataset])\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/abstract_dataset.py:949\u001b[0m, in \u001b[0;36mAbstractDataset._get_by_name\u001b[0;34m(workspace, name, version)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    946\u001b[0m         _get_logger()\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTried to retrieve v2 data asset but could not find v2 data asset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    947\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistered with name \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m in the workspace.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    948\u001b[0m                               \u001b[38;5;241m.\u001b[39mformat(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (version: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(version)))\n\u001b[0;32m--> 949\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result\n\u001b[1;32m    951\u001b[0m dataset \u001b[38;5;241m=\u001b[39m _dto_to_dataset(workspace, result)\n\u001b[1;32m    952\u001b[0m warn_deprecated_blocks(dataset)\n",
            "\u001b[0;31mUserErrorException\u001b[0m: UserErrorException:\n\tMessage: Cannot find dataset registered with name \"train_df\" (version: None) in the workspace.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Cannot find dataset registered with name \\\"train_df\\\" (version: None) in the workspace.\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716095020377
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task='classification',\n",
        "    primary_metric='accuracy',\n",
        "    training_data=ds,\n",
        "    label_column_name='y',\n",
        "    n_cross_validations=2)\n"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1716095126910
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "automl_run = exp.submit(config=automl_config, show_output=True)\n",
        "RunDetails(automl_run).show()\n",
        "automl_run.wait_for_completion(show_output=True)\n",
        "automl_run"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "No run_configuration provided, running on local with default configuration\nRunning in the active local environment.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>udacity-project</td><td>AutoML_331e1695-c571-4402-9e99-e9d57b26d42c</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_331e1695-c571-4402-9e99-e9d57b26d42c?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-259362/workspaces/quick-starts-ws-259362&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current status: DatasetEvaluation. Gathering dataset statistics.\nCurrent status: FeaturesGeneration. Generating features for the dataset.\nCurrent status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\nCurrent status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\nCurrent status: DatasetBalancing. Performing class balancing sweeping\nCurrent status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Class balancing detection\nSTATUS:       ALERTED\nDESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\nDETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n+------------------------------+--------------------------------+--------------------------------------+\n|Size of the smallest class    |Name/Label of the smallest class|Number of samples in the training data|\n+==============================+================================+======================================+\n|3692                          |yes                             |32950                                 |\n+------------------------------+--------------------------------+--------------------------------------+\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         High cardinality feature detection\nSTATUS:       PASSED\nDESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0   MaxAbsScaler LightGBM                          0:00:54             0.9125    0.9125\n    1   MaxAbsScaler XGBoostClassifier                 0:01:31             0.9110    0.9125\n    2   MaxAbsScaler ExtremeRandomTrees                0:00:55             0.7289    0.9125\n    3   SparseNormalizer XGBoostClassifier             0:01:16             0.9132    0.9132\n    4   MaxAbsScaler LightGBM                          0:00:52             0.9123    0.9132\n    5   MaxAbsScaler LightGBM                          0:00:54             0.8883    0.9132\n    6   StandardScalerWrapper XGBoostClassifier        0:01:15             0.9077    0.9132\n    7   MaxAbsScaler LogisticRegression                0:00:53             0.9086    0.9132\n    8   StandardScalerWrapper ExtremeRandomTrees       0:00:51             0.8910    0.9132\n    9   StandardScalerWrapper XGBoostClassifier        0:01:13             0.9115    0.9132\n   10   SparseNormalizer LightGBM                      0:00:52             0.9041    0.9132\n   11   StandardScalerWrapper XGBoostClassifier        0:01:14             0.9134    0.9134\n   12   MaxAbsScaler LogisticRegression                0:00:53             0.9084    0.9134\n   13   MaxAbsScaler SGD                               0:00:51             0.8604    0.9134\n   14   StandardScalerWrapper XGBoostClassifier        0:01:15             0.9127    0.9134\n   15   SparseNormalizer RandomForest                  0:01:03             0.8180    0.9134\n   16   StandardScalerWrapper LogisticRegression       0:00:51             0.9084    0.9134\n   17   StandardScalerWrapper RandomForest             0:00:54             0.9017    0.9134\n   18   StandardScalerWrapper XGBoostClassifier        0:01:21             0.9124    0.9134\n   19   TruncatedSVDWrapper RandomForest               0:02:09             0.8240    0.9134\n   20   TruncatedSVDWrapper RandomForest               0:02:58             0.8333    0.9134\n   21   StandardScalerWrapper XGBoostClassifier        0:01:19             0.9117    0.9134\n   22   VotingEnsemble                                 0:00:33             0.9166    0.9166\n   23   StackEnsemble                                  0:00:40             0.9150    0.9166\nStopping criteria reached at iteration 24. Ending experiment.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024/05/19 05:10:07 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n2024-05-19:05:38:03,525 WARNING  [_docstring_wrapper.py:27] Class StackEnsembleClassifier: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2024-05-19:05:38:05,250 WARNING  [_docstring_wrapper.py:27] Class StackEnsembleClassifier: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2024-05-19:05:38:05,251 WARNING  [_docstring_wrapper.py:27] Class StackEnsembleClassifier: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2024-05-19:05:38:06,853 WARNING  [_docstring_wrapper.py:27] Class StackEnsembleClassifier: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2024-05-19:05:38:06,854 WARNING  [_docstring_wrapper.py:27] Class StackEnsembleClassifier: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n2024-05-19:05:38:06,854 WARNING  [_docstring_wrapper.py:27] Class StackEnsembleClassifier: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716097191577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "best_run, best_model = automl_run.get_output()\n",
        "print(best_run)\n",
        "print(best_model)\n",
        "print(f\"Best run arguments: {best_run.get_details()['runDefinition']['arguments']}\")\n",
        "print(f\"Best run metrics: {best_run.get_metrics()}\")\n",
        "print(f\"Best run file names: {best_run.get_file_names()}\")\n",
        "joblib.dump(best_model, 'outputs/automl_model.joblib')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716097191590
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}